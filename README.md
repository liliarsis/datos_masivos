# Unit 2
# Introduction

In this section we will see algorithms for classification for Big Data. We can say that a classifier is an algorithm that, by receiving certain information from an object as input, is capable of indicating the category or class to which it belongs out of a limited number of possible classes. There are multiple classification algorithms, per example, decision tree, naive bayes, suport vector machine and more.

# Content

- [Homework 1](#homework-1)
- [Homework 2](#homework-2)
- [Homework 3](#homework-3)
- [Practice](https://github.com/liliarsis/datos_masivos/tree/unit2/practicas_tareas)
- [Evaluation](#evaluation)
- [Sources](#sources)
- [Collaborators](#collaborators)

## Homework 1
### Types of Machine Learning Algorithms

Algorithms can be classified into:
1. Supervised machine learning algorithms can apply what has been learned in the past to new data using labeled examples to predict future events.
Supervised machine learning algorithms can be classified into
- Classification: Naive Bayes, Suport Vector Machine, K-nearst neighboor
- Regression: Decision Tree, Linear Regression, Logistic Regression.

2. In contrast, unsupervised machine learning algorithms are used when the information used to train is neither classified nor labeled.
Unsupervised machine learning algorithms can be classified into:
- Clustering: K-means, Mean Shift, K-medoids
- Dimesionality Reduction: Principal Component Analysis (PCA), Feature Selection, Linear Discriminant Analysis (LDA).

3. Reinforcement machine learning algorithms is a learning method that interacts with its environment by producing actions and discovers errors or rewards. Trial and error search and delayed reward are the most relevant characteristics of reinforcement learning.
## Homework 2
### VectorAssembler
VectorAssembler is a transformer that combines a given list of columns into a single vector column. It is useful for combining raw features and features generated by different feature transformers into a single feature vector, in order to train ML models like logistic regression and decision trees. VectorAssembler accepts the following input column types: all numeric types, boolean type, and vector type. In each row, the values of the input columns will be concatenated into a vector in the specified order.
Assume that we have a DataFrame with the columns id, hour, mobile, userFeatures, and clicked:
```
id | hour | mobile | userFeatures     | clicked
----|------|--------|------------------|---------
 0  | 18   | 1.0    | [0.0, 10.0, 0.5] | 1.0
```

userFeatures is a vector column that contains three user features. We want to combine hour, mobile, and userFeatures into a single feature vector called features and use it to predict clicked or not. If we set VectorAssembler’s input columns to hour, mobile, and userFeatures and output column to features, after transformation we should get the following DataFrame:
```
 id | hour | mobile | userFeatures     | clicked | features
----|------|--------|------------------|---------|-----------------------------
 0  | 18   | 1.0    | [0.0, 10.0, 0.5] | 1.0     | [18.0, 1.0, 0.0, 10.0, 0.5]

```
### Scala Code
```
import org.apache.spark.ml.feature.VectorAssembler
import org.apache.spark.ml.linalg.Vectors

val dataset = spark.createDataFrame(
  Seq((0, 18, 1.0, Vectors.dense(0.0, 10.0, 0.5), 1.0))
).toDF("id", "hour", "mobile", "userFeatures", "clicked")

val assembler = new VectorAssembler()
  .setInputCols(Array("hour", "mobile", "userFeatures"))
  .setOutputCol("features")

val output = assembler.transform(dataset)
println("Assembled columns 'hour', 'mobile', 'userFeatures' to vector column 'features'")
output.select("features", "clicked").show(false)
```
### Root Mean Squared Error (RMSE)
Root Mean Square Error (RMSE) is the standard deviation of the residuals (prediction errors). Residuals are a measure of how far from the regression line data points are; RMSE is a measure of how spread out these residuals are. In other words, it tells you how concentrated the data is around the line of best fit. Root mean square error is commonly used in climatology, forecasting, and regression analysis to verify experimental results.

## Homework 3
### What is a Pipeline?
A machine learning pipeline is used to help automate machine learning workflows. They operate by enabling a sequence of data to be transformed and correlated together in a model that can be tested and evaluated to achieve an outcome, whether positive or negative.
Pipelines are iterative as every step is repeated to continuously improve the accuracy of the model and achieve a successful algorithm. To build better machine learning models, and get the most value from them, accessible, scalable and durable storage solutions are imperative, paving the way for on-premises object storage.

### Pipeline in Scala
MLlib standardizes APIs for machine learning algorithms to make it easier to combine multiple algorithms into a single pipeline, or workflow. This section covers the key concepts introduced by the Pipelines API, where the pipeline concept is mostly inspired by the scikit-learn project.
In machine learning, it is common to run a sequence of algorithms to process and learn from data. E.g., a simple text document processing workflow might include several stages:

- Split each document’s text into words.
- Convert each document’s words into a numerical feature vector.
- Learn a prediction model using the feature vectors and labels.

MLlib represents such a workflow as a Pipeline, which consists of a sequence of PipelineStages (Transformers and Estimators) to be run in a specific order.
### Confusion Matrix
A confusion matrix, also known as an error matrix, is a specific table layout that allows visualization of the performance of an algorithm, typically a supervised learning one (in unsupervised learning it is usually called a matching matrix). Each row of the matrix represents the instances in a predicted class while each column represents the instances in an actual class (or vice versa). The name stems from the fact that it makes it easy to see if the system is confusing two classes (i.e. commonly mislabeling one as another).

## Practice 1
## Evaluation
## Sources
- Apache Spark. (n.d.). Extracting, transforming and selecting features - Spark 2.4.5 Documentation. Retrieved June 1, 2020, from [https://spark.apache.org/docs/latest/ml-features#vectorassembler](https://spark.apache.org/docs/latest/ml-features#vectorassembler)
- Apache Spark. (n.d.-b). ML Pipelines - Spark 2.4.5 Documentation. Retrieved June 1, 2020, from [https://spark.apache.org/docs/latest/ml-pipeline.html](https://spark.apache.org/docs/latest/ml-pipeline.html)
- M, S. (2019, December 13). WHAT IS A PIPELINE IN MACHINE LEARNING?HOW TO CREATE ONE? Retrieved June 1, 2020, from [https://medium.com/analytics-vidhya/what-is-a-pipeline-in-machine-learning-how-to-create-one-bda91d0ceaca#:%7E:text=A%20machine%20learning%20pipeline%20is,outcome%2C%20whether%20positive%20or%20negative](https://medium.com/analytics-vidhya/what-is-a-pipeline-in-machine-learning-how-to-create-one-bda91d0ceaca#:%7E:text=A%20machine%20learning%20pipeline%20is,outcome%2C%20whether%20positive%20or%20negative)
- Patel, P. (2019, November 14). Machine Learning is Magic! Retrieved June 1, 2020, from [https://medium.com/@parshvpatel07/machine-learning-is-magic-9b1e5d07709f](https://medium.com/@parshvpatel07/machine-learning-is-magic-9b1e5d07709f)
- Patel, P. (2019, November 21). Machine Learning is Magic! Part 2. Retrieved June 1, 2020, from [https://medium.com/@parshvpatel07/machine-learning-is-magic-part-2-690ad63e6e50](https://medium.com/@parshvpatel07/machine-learning-is-magic-part-2-690ad63e6e50)
- Statistics How To. (2020, May 19). RMSE: Root Mean Square Error. Retrieved June 1, 2020, from [https://www.statisticshowto.com/probability-and-statistics/regression-analysis/rmse-root-mean-square-error/](https://www.statisticshowto.com/probability-and-statistics/regression-analysis/rmse-root-mean-square-error/)
- Wikipedia contributors. (2020, May 1). Confusion matrix - Wikipedia. Retrieved June 1, 2020, from [https://en.wikipedia.org/wiki/Confusion_matrix](https://en.wikipedia.org/wiki/Confusion_matrix)
## Collaborators
* **Manuel Orozco** - [Github](https://github.com/manuelorozcotoro)
* **Lilia Rosales** - [Github](https://github.com/liliarsis)
